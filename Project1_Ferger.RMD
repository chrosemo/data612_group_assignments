---
title: 'DATA 612: Project 1 | Global Baseline Predictors and RMSE'
author: "Amber Ferger, Charlie H, Juanelle Marks" 
date: "6/3/2020"
output: 
    html_document:
     theme: lumen
     highlight: tango
     toc: TRUE
    
---

# Introduction

In this first assignment, we’ll attempt to predict ratings with very little information. We’ll first look at just raw averages across all (training dataset) users. We’ll then account for “bias” by normalizing across users and across items.  
  
We'll be working with ratings in a user-item matrix, where each rating may be (1) assigned to a training dataset, (2) assigned to a test dataset, or (3) missing.

# Data Source
The data was sourced from: https://www.kaggle.com/rounakbanik/the-movies-dataset?select=ratings_small.csv
The data set contains 100 ratings from 700 users. It constitutes  a subset of the ratings available in the Full MovieLens dataset. Ratings are on the scale 1 to 5. For the purspose of this project, we extracted a 10 X 10 subset of the dataframe.



### Load Libraries
```{r message=FALSE, include=FALSE}
library(tidyverse)
library(pander)
library(knitr)
library(dplyr)

```


# Data Processing

### Load Data, develop base set
```{r}

rawData <- data.frame(read.csv("ratings_small.csv"))

# top 10 movies
top10 <- rawData %>%
  group_by(movieId) %>%
  summarize(TOTAL_RATINGS = n()) %>%
  arrange(desc(TOTAL_RATINGS)) %>%
  mutate(RECORD_ID = as.numeric(rownames(.))) %>%
  filter(RECORD_ID <= 10)

# all users that have at least 1 of the top 10 movies
dataSubset <- inner_join(rawData, top10, by=c('movieId'='movieId'))

# user IDs to be used in final dataset
sampledData <- dataSubset %>%
  group_by(userId) %>%
  summarize(MOVIE_COUNT = n()) %>%
  filter(MOVIE_COUNT >= 6) %>%
  group_by(MOVIE_COUNT) %>% 
  sample_n(2)

# final data set in long format
finalData <- inner_join(dataSubset, sampledData, by=c("userId" = "userId")) %>%
  select(userId,movieId,rating)

# final data matrix
finalData.df <- spread(finalData,movieId,rating)
head(finalData.df)

```

### Split Data into Training and Test

```{r}

# gather data -- long format
allValues <- gather(finalData.df,movieId,rating, -userId)

testSet <- allValues %>%
  filter(!is.na(rating)) %>% # do not include nulls
  group_by(userId) %>%
  sample_n(1)

trainingSet <- anti_join(allValues, testSet, by=c('userId'='userId', 'movieId'='movieId')) 

head(trainingSet)
#head(testSet)

```

# Raw average and RMSE

### Raw Average
```{r}
#take the mean of the  training dataset; every entry gets the same prediction
raw_avg <- mean(trainingSet$rating, na.rm =TRUE)
raw_avg
```

### RMSE-training set
```{r}
RMSE = function(data, data_avg){ 
  sqrt(mean((data - data_avg)^2, na.rm =TRUE)) 
}

trainRMSE <-  RMSE(trainingSet$rating,raw_avg )
trainRMSE
```

### RMSE-test set
```{r}
testRMSE<-  RMSE(testSet$rating,raw_avg)
testRMSE
```

In both cases the RMSE is high. It is especially higher in the test set.

# Bias Calculation

```{r}
train_matrix <- trainingSet %>% spread(movieId, rating) %>% column_to_rownames(var = "userId")
user_bias <- rowMeans(train_matrix, na.rm = TRUE) - raw_avg
item_bias <- colMeans(train_matrix, na.rm = TRUE) - raw_avg

#Show information on separate tables
```


# Baseline Predictors for each user-item combination
```{r}
# Applying baseline predictor function to each user-item combination of train_matrix (10x10)
blp <- function(x,y) x + y + raw_avg
baseline_predictor <- data.frame(sapply(1:10, function(i) sapply(1:10, function(j) blp(user_bias[j], item_bias[i]))), row.names = rownames(train_matrix))
names(baseline_predictor) <- names(train_matrix)
# Clipping any values greater than 5
baseline_predictor[baseline_predictor > 5] <- 5
```

# Creating test matrix
```{r}
# Spreading testSet and moving userId to row names
test_matrix <- testSet %>% spread(movieId, rating) %>% column_to_rownames(var = "userId")
# Applying baseline predictor function to each user-item combination of test_matrix (10x8)
baseline_predictor_test <- data.frame(t(sapply(rownames(test_matrix), function(i) sapply(names(test_matrix), function(j) blp(user_bias[i], item_bias[j])))))
names(baseline_predictor_test) <- names(test_matrix)
# Clipping any values greater than 5
baseline_predictor_test[baseline_predictor_test > 5] <- 5
# Quick check of whether baseline predictions were created consistently across train_matrix and test_matrix
baseline_predictor_test$`356` == baseline_predictor$`356`
```

# Baseline Predictor RMSE
```{r}
# Creating a function to calculate RMSE on each matrix using the baseline predictions
predictor_RMSE <- function(matrix, predictions) sqrt(sum((matrix - predictions)^2, na.rm = TRUE)/sum(!is.na(matrix)))
# Baseline predictor RMSE for train_matrix and test_matrix
(train_predictor_RMSE <- predictor_RMSE(train_matrix, baseline_predictor))
(test_predictor_RMSE <- predictor_RMSE(test_matrix, baseline_predictor_test))
```
