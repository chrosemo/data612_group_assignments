knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pander)
library(knitr)
library(dplyr)
library(recommenderlab)
library(readxl)
library(tictoc)
library(sparklyr)
isntall.packages('sparklyr')
install.packages('sparklyr')
library(tidyverse)
library(pander)
library(knitr)
library(dplyr)
library(recommenderlab)
library(readxl)
library(tictoc)
library(sparklyr)
jokeText <- data.frame(read_xls("Dataset3JokeSet.xls", col_names = FALSE))
jokeText <- data.frame(read_xls("Dataset3JokeSet.xlsx", col_names = FALSE))
jokeText <- data.frame(read_xls("Dataset3JokeSet.xlsx", col_names = FALSE))
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
View(jokeText)
View(jokeText)
library(stringr)
View(jokeText)
str_detect(jokeText, 'Q:')
colnames(jokeText) <- c('JOKE_TEXT')
str_detect(jokeText$JOKE_TEXT, 'Q:')
View(jokeText)
jokeText[4]
jokeText[4,]
jokeText[5,]
jokeText[6,]
jokeText[1,]
install.packages('tidytext')
library(tidytext)
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
jokeText$JOKE_TYPE <- str_detect(jokeText$JOKE_TEXT, 'Q:')
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
jokeText <- jokeText %>%
mutate(JOKE_TYPE = str_detect(jokeText$JOKE_TEXT, 'Q:')) %>%
mutate(ifelse(JOKE_TYPE == 'TRUE', 0, 1))
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
jokeText <- jokeText %>%
mutate(JOKE_TYPE = str_detect(jokeText$JOKE_TEXT, 'Q:')) %>%
mutate(JOKE_TYPE = ifelse(JOKE_TYPE == 'TRUE', 1, 0))
jokeText[1,] %>%
unnest_tokens(word, JOKE_TEXT)
jokeText %>%
group_by(JOKE_TEXT) %>%
unnest_tokens(word, JOKE_TEXT) %>%
summarize(WORD_COUNT= n())
View( jokeText %>%
group_by(JOKE_TEXT) %>%
unnest_tokens(word, JOKE_TEXT) %>%
summarize(WORD_COUNT= n()))
View( jokeText %>%
group_by(JOKE_TEXT) %>%
unnest_tokens(word, JOKE_TEXT))
sapply(strsplit(jokeText, " "), length)
strsplit(jokeText, " ")
str_count(jokeText$JOKE_TEXT, '\\w+')
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE column
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'))
str_count(jokeText$JOKE_TEXT, '!')
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE & JOKE_LENGTH columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
install.packages('tidymodels')
install.packages("tidymodels")
View(jokeText %>% unnest_tokens(word, JOKE_TEXT))
View(split(jokeText, seq(nrow(jokeText))))
jokeText.ls <- split(jokeText, seq(nrow(jokeText)))
View(lapply(jokeText.ls, unnest_tokens(word, JOKE_TEXT)))
lapply(jokeText.ls, function(x){ unnest_tokens(word, x$JOKE_TEXT)})
apply(jokeText.ls, function(x){ unnest_tokens(word, x$JOKE_TEXT)})
rapply(jokeText.ls, function(x){ unnest_tokens(word, x$JOKE_TEXT)})
jokeText.ls[1]
jokeText.ls[1]$JOKE_TEXT
jokeText.ls[1][1]
jokeText.ls[1][[1]
]
View(jokeText.ls[1])
jokeText.ls[[1]]
jokeText.ls[[1]][1]
jokeText.ls[[1]]$JOKE_TEXT
jokeText.ls[[1]] %>%
unnest_tokens(word, JOKE_TEXT)
install.packages('tm')
library(tm)
Corpus(VectorSource(jokeText$JOKE_TEXT))
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT))
inspect(jokeCorpus[1:2])
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(jokeCorpus)
dtm
inspect(dtm)
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
inspect(removeSparseTerms(dtm, 0.4))
inspect(removeSparseTerms(dtm, 0.1))
inspect(dtm)
inspect(removeSparseTerms(dtm, 0.1))
inspect(removeSparseTerms(dtm, 0.01))
inspect(dtm)
jokeText %>%
mutate(JOKE_TEXT2 = gsub('[[:punct:] ]+',' ',JOKE_TEXT))
View(jokeText %>%
mutate(JOKE_TEXT2 = gsub('[[:punct:] ]+',' ',JOKE_TEXT)))
View(jokeText %>%
mutate(JOKE_TEXT2 = gsub(',',' ',JOKE_TEXT)))
View(jokeText %>%
mutate(JOKE_TEXT2 = gsub('.',' ',gsub(',',' ',JOKE_TEXT))))
View(jokeText %>%
mutate(JOKE_TEXT2 = gsub(',',' ',JOKE_TEXT)))
jokeText <- jokeText %>%
mutate(JOKE_TEXT2 = gsub(',',' ',JOKE_TEXT))
# create a corpus of words in the text
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT2))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
# create a corpus of words in the text
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpys <- tm_map(jokeCorpus, removePunctuation)
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
dtm_td <- tidy(dtm)
View(dtm_td)
dtm_td %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
joke_sentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
rm(ls=list())
rm(list = ls())
library(tidyverse)
library(dplyr)
library(readxl)
library(sparklyr)
# https://www.cs.ox.ac.uk/files/244/mihalcea.cicling07.pdf
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
# create a corpus of words in the text
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
#  turn it into a one-term-per-document-per-row data frame
dtm_td <- tidy(dtm)
# sentiments per word
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
# sentiments per doc
joke_sentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
rm(list = ls())
install.packages('tidyverse')
install.packages("tidyverse")
tidyverse_update(recursive = FALSE, repos = getOption("repos"))
install.packages('tibble')
knitr::opts_chunk$set(echo = TRUE)
# https://www.cs.ox.ac.uk/files/244/mihalcea.cicling07.pdf
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
library(tidyverse)
library(dplyr)
library(readxl)
library(sparklyr)
#library(stringr)
library(tm)
library(tidyr)
# https://www.cs.ox.ac.uk/files/244/mihalcea.cicling07.pdf
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
jokeCorpus <- Corpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
#  turn it into a one-term-per-document-per-row data frame
dtm_td <- tidy(dtm)
install.packages('tidytext')
library(tidytext)
#  turn it into a one-term-per-document-per-row data frame
dtm_td <- tidy(dtm)
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
# sentiments per doc
joke_sentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
```{r, warning = FALSE}
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
e
# create a corpus of words in the text
jokeCorpus <- VCorpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
dtm_td <- tidy(dtm)
# sentiments per word
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
# sentiments per doc
joke_sentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(readxl)
library(sparklyr)
#library(stringr)
library(tm)
library(tidyr)
library(tidytext)
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
jokeCorpus <- VCorpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
dtm_td <- tidy(dtm)
# sentiments per word
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
joke_sentiments
dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
joke_sentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
joke_sentiments
dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
jokeSentiments <- dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
jokeSentiments
dtm_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
joke_sentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
# sentiments per word
jokeSentiments <- dtm_td %>%
inner_join(get_sentiments("bing"),., by = c(term = "word"))
get_sentiments("bing")
dtm_td
tidy(dtm)
dtm_td
jokeCorpus
DocumentTermMatrix(jokeCorpus)
dtm <- DocumentTermMatrix(jokeCorpus)
dtm
inspect(dtm)
dtm_td <- tidy(dtm)
dtm_td
tidy(dtm)
tidy(dtm)
dtm_td <- tidy(dtm)
dtm_td
dtm
inspect(dtm)
inspect(dtm_td)
View(dtm_td)
dtm_td %>% summarize(COUNT_DIST = n_distinct)
dtm_td %>% summarize(COUNT_DIST = n_distinct())
dtm_td %>% summarize(COUNT_DIST = n_distinct(document))
n_distinct(dtm_td$document)
jokeCorpus
dtm
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
jokeText$JOKE_NUM <- 1:nrow(jokeText)
# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
EXCITED_COUNT = str_count(JOKE_TEXT, '!'))
View(jokeText)
jokeCorpus <- VCorpus(VectorSource(jokeText$JOKE_TEXT))
# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)
# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)
colnames(sentPerDoc)
sentPerDoc <- jokeSentiments %>%
count(document, sentiment, wt = count) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
arrange(sentiment)
colnames(sentPerDoc)
dtm_lda <- LDA(dtm, k = 2, control = list(seed = 1234))
library(topicmodels)
colnames(jokeText)
finalJokes <- inner_join(jokeText,sentPerDoc, by = c('JOKE_NUM' = 'document'))
sentPerDoc$document <- as.integer(sentPerDoc$document)
finalJokes <- inner_join(jokeText,sentPerDoc, by = c('JOKE_NUM' = 'document'))
View(finalJokes)
finalJokes <- left_join(jokeText,sentPerDoc, by = c('JOKE_NUM' = 'document'))
finalJokes[is.na(finalJokes)] <- 0
install.packages('topicmodels')
dtm_lda <- LDA(dtm, k = 2, control = list(seed = 1234))
library(topicmodels)
dtm_lda <- LDA(dtm, k = 2, control = list(seed = 1234))
dtm_lda
joke_lda <- LDA(dtm, k = 2, control = list(seed = 1234))
joke_lda
joke_topics <- tidy(joke_lda, matrix = "beta")
joke_topics
library(ggplot2)
library(dplyr)
joke_top_terms <- joke_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
joke_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
joke_lda <- LDA(dtm, k = 10, control = list(seed = 1234))
joke_lda
joke_topics <- tidy(joke_lda, matrix = "beta")
joke_topics
joke_lda <- LDA(dtm, k = 10, control = list(seed = 1234))
joke_topics <- tidy(joke_lda, matrix = "beta")
library(ggplot2)
library(dplyr)
joke_top_terms <- joke_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
joke_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
joke_top_terms <- joke_topics %>%
group_by(topic) %>%
top_n(5, beta) %>%
ungroup() %>%
arrange(topic, -beta)
joke_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
