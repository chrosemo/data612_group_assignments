---
title: "DATA612 Final Project | Jester Dataset"
author: "Amber Ferger, Charlie Rosemond, Juanelle Marks" 
date: "7/1/2020"
output: 
    html_document:
     theme: lumen
     highlight: tango
     toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, include=FALSE}
# load libraries
library(tidyverse)
library(dplyr)
library(readxl)
library(sparklyr)

#library(stringr)
library(tm)
library(tidyr)
library(tidytext)

# install a local version of Spark for development purposes
# spark_install()
```

## Project Goals ****UPDATE TO REFLECT SHIFT TO HYBRID****
We will be using Spark, via R and *sparklyr* to build a recommender system that predicts Jester users’ joke ratings. Spark offers the distributed platform necessary to work with the larger Jester dataset, which would otherwise prove too large for our group’s local machines to handle. Our intended system will draw on our previous assignments and select from a comparison of recommenders of different types. We expect to use matrix factorization in pre-processing, and we will employ various evaluation methods to select our final model.

## About the Dataset ****APPEND TO REFLECT SHIFT TO HYBRID****
Jester is a joke recommender system developed by the University of California, Berkeley Laboratory of Automation Science and Engineering. The Jester dataset contains millions of joke ratings made by users of the recommender system, which learns from new users. Our chosen dataset – several Jester sets of different sizes are available – initially describes approximately 80,000 users making over 2.3 million ratings of 150 different jokes. The Jester team collected these ratings from April 1999 to May 2003 and November 2006 to March 2015. Each user and joke is represented by a unique integer identifier, and ratings range from -10 (worst) to +10 (best). Learn more about Jester [here](http://eigentaste.berkeley.edu/about.html).


## Data Processing


## Feature Engineering
The first thing we will do is create features for our jokes. We will base our feature development on research by Rada Mihalcea and Stephen Pulman.


### Joke Characteristics
### Joke Ratings

```{r}
# Downloading ratings data to tempfile
dl <- tempfile()
download.file("http://eigentaste.berkeley.edu/dataset/JesterDataset3.zip", dl)
```

```{r}
# Unzipping then reading into a tibble
con <- unzip(dl, "FINAL jester 2006-15.xls")
working <- read_xls(con, col_names = FALSE)
```

```{r}
# Removing count column
ratings_working <- working[-1]

# Adding column and row names
names(ratings_working) <- 1:dim(ratings_working)[2]
row.names(ratings_working) <- 1:nrow(ratings_working)

# Removing retired jokes (columns)
retired <- c("1","2","3","4","5","6","9","10","11","12","14","20","27","31","43","51","52","61","73","80","100","116")  # per Jester website -- jokes removed and thus not rated
ratings_working[, retired] <- list(NULL)
```

```{r}
# Replacing "99" with NA
ratings_working[ratings_working == 99] <- NA

# Creating binary matrix where positive ratings (>=1) are 1 and all other ratings or NA are 0
ratings_binary <- as.matrix(ratings_working)
ratings_binary[is.na(ratings_binary) | ratings_binary < 1] <- 0 
ratings_binary[ratings_binary != 0] <- 1
```

```{r}
# Creating binary rating matrix
ratings <- as(ratings_binary, "binaryRatingMatrix")
```

### Joke Text

The joke text is included in the *jokeText* file, so we will import this into our session. Let's create a few features from the joke text:

* **JOKE_TYPE**: There are 2 general types of jokes - (1) Q&A (ex: Q. What's the difference between a man and a toilet?   A. A toilet doesn't follow you around after you use it.) and (2) story-line jokes (ex: A man visits the doctor. The doctor says "I have bad news for you.You have cancer and Alzheimer's disease".  The man replies "Well,thank God I don't have cancer!) We will classify Q&A jokes as $1$ and story-line jokes as $0$.
* **JOKE_LENGTH**: The number of words in the joke. 
* **EXCITED_COUNT**: The number of times an exclamation point is used in a given joke. 
* **SENTIMENT_SCORE**: We will analyze the general sentiment of the joke using the 

```{r message=FALSE} 

# https://www.cs.ox.ac.uk/files/244/mihalcea.cicling07.pdf
jokeText <- data.frame(read_xls("jokeText.xls", col_names = FALSE))
colnames(jokeText) <- c('JOKE_TEXT')
jokeText$JOKE_NUM <- 1:nrow(jokeText)

# JOKE_TYPE, JOKE_LENGTH, EXCITED_COUNT columns
jokeText <- jokeText %>%
  mutate(JOKE_TYPE = ifelse(str_detect(JOKE_TEXT, 'Q:') == 'TRUE', 1, 0),
         JOKE_LENGTH = str_count(JOKE_TEXT, '\\w+'),
         EXCITED_COUNT = str_count(JOKE_TEXT, '!'))

```

### Joke Sentiment
To analyze the joke sentiment, we'll create a corpus for our joke text using the *tm* package. We'll remove whitespace, stopwords, and punctuation and also transform the text to lowercase. This will allow us to create a *DocumentTermMatrix* which identifies the counts of words in each joke.  
  
When we inspect the first few elements of the *DocumentTermMatrix*, we can that it is very sparse: 99% of the counts are 0. This means that there are not a lot of common words used in all jokes.
```{r}
# https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf  
# https://cran.r-project.org/web/packages/tidytext/vignettes/tidying_casting.html

# create a corpus of words in the text
jokeCorpus <- VCorpus(VectorSource(jokeText$JOKE_TEXT))

# no whitespace, all lowercase, remove stopwords
jokeCorpus <- tm_map(jokeCorpus, stripWhitespace)
jokeCorpus <- tm_map(jokeCorpus, content_transformer(tolower))
jokeCorpus <- tm_map(jokeCorpus, removeWords, stopwords("english"))
jokeCorpus <- tm_map(jokeCorpus, removePunctuation)

# create document-term matrix
dtm <- DocumentTermMatrix(jokeCorpus)
inspect(dtm)

```

We will transform the *DocumentTermMatrix* into a format that will allow us to analyze the sentiment of each word. We will use the the *get_sentiments()* function, which  looks at the words with a positive score from the lexicon of Bing Liu and collaborators.
```{r message=FALSE}

#  turn it into a one-term-per-document-per-row data frame
dtm_td <- tidy(dtm)

# sentiments per word
jokeSentiments <- dtm_td %>%
   inner_join(get_sentiments("bing"),by = c(term = "word"))

# sentiments per doc
sentPerDoc <- jokeSentiments %>%
   count(document, sentiment, wt = count) %>%
   spread(sentiment, n, fill = 0) %>%
   mutate(sentiment = positive - negative) %>%
   arrange(sentiment)

# convert to a number
sentPerDoc$document <- as.integer(sentPerDoc$document)

```

We can now join this to our original jokes dataset to get the positive, negative, and total sentiment scores of each joke. We will replace nulls in jokes where no positive or negative words were found with 0 (neutral).

```{r}

finalJokes <- left_join(jokeText,sentPerDoc, by = c('JOKE_NUM' = 'document'))
finalJokes[is.na(finalJokes)] <- 0

colnames(finalJokes)

```


## Recommenders

### IBCF

```{r}
# Splitting into train/test
which_train <- sample(x = c(TRUE, FALSE), size = nrow(ratings), replace = TRUE, prob = c(0.8, 0.2))
ratings_train <- ratings[which_train,]
ratings_test <- ratings[!which_train,]
```
```{r}
# Training IBCF recommender using Jaccard for distance given binary ratings
ratings_ibcf <- Recommender(data = recc_train, method = "IBCF", parameter = list(method = "Jaccard"))
```
```{r}
# Defining a ratings similarity matrix
ratings_dist <- as(ratings_ibcf@model$sim, "matrix")
```

## Evaluation and Selection

## Conclusion

## Sources

* Mihalcea, Rada, and Stephen Pulman. “Characterizing Humour: An Exploration of Features in Humorous Texts.” Computational Linguistics and Intelligent Text Processing Lecture Notes in Computer Science, 2007, pp. 337–347., doi:10.1007/978-3-540-70939-8_30.

***ADD COURSE TEXT***

