---
title: 'DATA 612: Project 4 | Accuracy and Beyond'
author: "Amber Ferger, Charlie Rosemond, Juanelle Marks" 
date: "6/14/2020"
output: 
    html_document:
     theme: lumen
     highlight: tango
     toc: TRUE
    
---

# Project Instructions

The goal of this assignment is give you practice working with accuracy and other recommender system metrics.

In this assignment you’re asked to do at least one or (if you like) both of the following:

• Work in a small group, and/or
• Choose a different dataset to work with from your previous projects.

#### Deliverables

1. As in your previous assignments, compare the accuracy of at least two recommender system algorithms against your offline data.

2. Implement support for at least one business or user experience goal such as increased serendipity, novelty, or diversity.

3. Compare and report on any change in accuracy before and after you’ve made the change in #2.

4. As part of your textual conclusion, discuss one or more additional experiments that could be performed and/or metrics that could be evaluated only if online evaluation was possible. Also, briefly propose how you would design a reasonable online evaluation environment.

# Project Implementation




## Data Source
We will be using the (jester)[http://eigentaste.berkeley.edu/dataset/] dataset for this assignment. This dataset contains data from 24,983 users who have rated 36 or more jokes. Ratings are real values ranging from $-10.00$ to $+10.00$ (the value "99" corresponds to "null" = "not rated"). Each row in the dataset represents a different user, and the first column represents the total number of jokes the individual has rated. The remaining 100 columns give the ratings for each joke. 


## Motivation

In this assignment, we will compare the output of 2 recommender systems:

* **UBCF** - user-based collaborative filtering
* **IBCF** - item-based collaborative filtering

For each recommender system, we will use k-fold cross-validation 

## Load Libraries

```{r message=FALSE, include=FALSE}
# load libraries
library(tidyverse)
library(pander)
library(knitr)
library(dplyr)
library(recommenderlab)
library(readxl)
```

## Load data

First, we will load in the jester data set. We will remove the column with the number of rated jokes because this will not be used in the recommendation system. Additionally, the raw data stores non-rated jokes as the number $99$, so instead, we will replace these values with nulls. 

```{r}
# Read jester data
jester <- read_xls("jester-data-1.xls", col_names = FALSE)
colnames(jester) <- c("ratingCount", seq(100))
row.names(jester) <- 1:nrow(jester)

# remove num jokes column
ratings <- jester[-1]

# replace 0 (no rating) with NULL
ratings[ratings == 99] <- NA
ratings <- as.matrix(ratings)

# # function to replace the missing value with the median of the column
# medValue.f <- function(x){
#   x[is.na(x)] <- median(x, na.rm=TRUE) 
#   return(x)
# }
# # Replace NA with median
# ratings <- apply(ratings, 2, medValue.f)

# Create large dgCMatrix
finalRatings <- as(ratings, 'realRatingMatrix')
```

## Recommender Systems

### Parameters

We'll define the following: 

* **Training Percent:** The percent of the data that should be used in training. The remaining data will be used for testing.
* **Items To Keep:** The total number of items that will be used to generate the recommendations. The remaining items will be used to test the model accuracy. We'll identify the min number of jokes that an individual has rated and use a few less than that. 
* **Rating Threshold:** The threshold to be used for positive ratings. Since our data is on a scale of -10 to 10, we will use 5 as the threshold. 
```{r}

trainPct <- 0.8
toKeep <- min(rowCounts(finalRatings)) - 5
ratingThreshold <- 5




```

## Support for increased Serendepity|Novelty|Diversity- Business|User Experience

## Discussion

### Variation in accuracy

### Additional experiments that can be performed|metrics that can be evaluated if only online evaluation was possible

### Proposed Design for Online Evaluation Environment

## Conclusion

## Reference

